{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ragR54GDghNj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1WDa1aAcgjK4"
   },
   "outputs": [],
   "source": [
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ND7VS9jzgjIB"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4yK32_zcgjGR"
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts([text])\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    sequences = tokenizer.texts_to_sequences([text])[0]\n",
    "    return sequences, total_words, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0dPIXT5PgjEa"
   },
   "outputs": [],
   "source": [
    "def create_sequences(sequences, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(sequences)):\n",
    "        end_index = i + seq_length\n",
    "        if end_index > len(sequences) - 1:\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_index], sequences[end_index]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PbWkOqtHgjCl"
   },
   "outputs": [],
   "source": [
    "def create_model(seq_length, total_words):\n",
    "    model = Sequential([\n",
    "        Embedding(total_words, 100, input_length=seq_length),\n",
    "        LSTM(256, return_sequences=True),\n",
    "        LSTM(256),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XYhHUbNngjAv"
   },
   "outputs": [],
   "source": [
    "def generate_random_sentence(model, tokenizer, seq_length, num_words):\n",
    "    start_index = np.random.randint(0, len(sequences) - seq_length - 1)\n",
    "    seed_text = ' '.join([tokenizer.index_word[idx] for idx in sequences[start_index:start_index+seq_length]])\n",
    "\n",
    "    result = seed_text\n",
    "    for _ in range(num_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        encoded_text = pad_sequences([encoded_text], maxlen=seq_length, truncating='pre')\n",
    "        y_pred = np.argmax(model.predict(encoded_text), axis=-1)\n",
    "        predicted_word = tokenizer.index_word[y_pred[0]]\n",
    "        seed_text += ' ' + predicted_word\n",
    "        result += ' ' + predicted_word\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUWcJXMkgi-t",
    "outputId": "e3d1c835-eb86-45aa-d86c-b3d97ec1c851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "130/130 [==============================] - 563s 4s/step - loss: 6.6821 - accuracy: 0.0521\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 553s 4s/step - loss: 6.3174 - accuracy: 0.0535\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 551s 4s/step - loss: 6.0727 - accuracy: 0.0636\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 551s 4s/step - loss: 5.8904 - accuracy: 0.0721\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 550s 4s/step - loss: 5.7689 - accuracy: 0.0810\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 548s 4s/step - loss: 5.6420 - accuracy: 0.0902\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 545s 4s/step - loss: 5.5181 - accuracy: 0.1002\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 560s 4s/step - loss: 5.4189 - accuracy: 0.1062\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 557s 4s/step - loss: 5.3392 - accuracy: 0.1088\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 547s 4s/step - loss: 5.2510 - accuracy: 0.1125\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = 'test_data_long.txt'  \n",
    "    text = read_text_file(file_path)\n",
    "\n",
    "    text = preprocess_text(text)\n",
    "\n",
    "    sequences, total_words, tokenizer = tokenize_text(text)\n",
    "\n",
    "    seq_length = 50  \n",
    "    X, y = create_sequences(sequences, seq_length)\n",
    "\n",
    "    model = create_model(seq_length, total_words)\n",
    "    model.fit(X, to_categorical(y, num_classes=total_words), epochs=10, batch_size=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTHePSnWgi84",
    "outputId": "825697ca-e94d-4d7e-e649-35209070fbf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "between the two that's the devil of it answered our host there was drury was one of the two he laid out the boy was walking out with little nellie seymour and one day they met benton and that night benton came into the bar and started making foul innuendoes to the house and the house and the house and the man and i had been a man of the\n"
     ]
    }
   ],
   "source": [
    "generated_sentence = generate_random_sentence(model, tokenizer, seq_length, num_words=20)\n",
    "print(generated_sentence)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
